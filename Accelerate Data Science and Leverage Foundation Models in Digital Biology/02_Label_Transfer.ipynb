{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerating Data Science and Leveraging Foundation Models in Digital Biology  \n",
    "\n",
    "Copyright (c) 2025, NVIDIA CORPORATION. Licensed under the Apache License, Version 2.0 (the \"License\") you may not use this file except in compliance with the License. You may obtain a copy of the License athttp://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Label Transfer ##\n",
    "\n",
    "**Table of Contents**\n",
    "<br>\n",
    "This notebook translates the pre-processed singleâ€‘cell data into a format that supports label transfer across datasets, making use of a foundation model ([Geneformer](https://docs.nvidia.com/bionemo-framework/latest/user-guide/developer-guide/bionemo-geneformer/bionemo-geneformer-Overview/)) and a machine learning classifier.This notebook covers the below sections: \n",
    "\n",
    "1. [Label Transfer](#Label-Transfer)\n",
    "    * [Splitting the reference and inference labels](#Splitting-the-reference-and-inference-labels)\n",
    "    * [Converting from h5ad to SCDL format](#Converting-from-h5ad-to-SCDL-format)\n",
    "    * [Cell Type Classificaton with Geneformer](#Cell-Type-Classificaton-with-Geneformer)\n",
    "    * [Train Label Transfer](#Train-Label-Transfer)\n",
    "    * [Test Label Transfer](#Test-Label-Transfer)\n",
    "2. [Conclusion](#Conclusion)\n",
    "\n",
    "For more details, please visit NVIDIA BioNeMo Framework at https://docs.nvidia.com/bionemo-framework/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the lab, we will perform a label transfer task. This is useful for allowing multiple datasets to map to a unified set of labels. With this, many datasets can be combined for even more powerful analyses. \n",
    "\n",
    "We will use a Random Forest Classifier for the task, which will map between Geneformer embedding vectors, and the cell type labels in the dataset we have been using. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the reference and inference labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference labels will be the set of labels that we train the classifier on, and inference labels will be the set of labels we test the classifier on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the data from part one using `anndata`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_h5ad(\"filtered_dataset.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the data shape is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212613, 28152)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the classifier, create `refData` containing all the cells from the `10x 5' v2` and `10x 3' v3` assays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "refData = adata[adata.obs[\"assay\"].isin([\"10x 5' v2\",\"10x 3' v3\"])].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data shape shows that `refdata` has 172,170 cells, or about 80% of the total dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172170, 39)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refData.obs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the classifier, create `inferData` containing all the cells from the `10x 5' v1` assay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferData = adata[adata.obs[\"assay\"].isin([\"10x 5' v1\"])].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data shape shows that `inferdata` has 40,443 cells or about 20% of the total dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40443, 39)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferData.obs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting from h5ad to SCDL format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until this point in the lab, we have been using the AnnData format to store the dataset. However, when running inference using BioNeMo, we can optimize the performance by using the [BioNeMo-scdl (Single Cell Data Loader)](https://docs.nvidia.com/bionemo-framework/2.0/user-guide/developer-guide/bionemo-scdl/bionemo-scdl-Overview/) format. \n",
    "\n",
    "This offers a few advantages over AnnData, mainly the ability to handle data sets that are too large to fit in memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up directories and functions to run this notebook in a reproducible manner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def random_seed(seed:int):\n",
    "    state = random.getstate()\n",
    "    random.seed(seed)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        # Go back to previous state\n",
    "        random.setstate(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from bionemo.core import BIONEMO_CACHE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_workdir = BIONEMO_CACHE_DIR / \"notebook_tutorials\" / \"geneformer_celltype_classification\"\n",
    "\n",
    "if notebook_workdir.exists():\n",
    "    shutil.rmtree(notebook_workdir)\n",
    "notebook_workdir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the ref data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir_ref = notebook_workdir / \"celltype-bench-dataset-ref\"\n",
    "input_dir_ref.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_ref = notebook_workdir / \"celltype-bench-dataset-ref-data\"\n",
    "result_path_ref = notebook_workdir / \"results_ref.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with random_seed(32):\n",
    "    indices = list(range(len(refData)))\n",
    "    random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `random_seed` context manager is a utility to ensure that any random operations within its scope are reproducible. \n",
    "\n",
    "This is particularly useful here in the context of single-cell data analysis where we perform data splitting, shuffling, and model initialization.\n",
    "\n",
    "\n",
    "Now, setting up some of the parameters for managing the computational load when generating embeddings with Geneformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_batch_size:int = 32\n",
    "num_steps:int = 2048\n",
    "selection = sorted(indices[:micro_batch_size*num_steps])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the reference data to the input directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5ad_outfile_ref = input_dir_ref / \"hs-celltype-bench.h5ad\"\n",
    "refData.write_h5ad(h5ad_outfile_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!convert_h5ad_to_scdl --data-path {input_dir_ref} --save-path {data_dir_ref}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the new files needed for the optimized data loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['version.json',\n",
       " 'features',\n",
       " 'data.npy',\n",
       " 'metadata.json',\n",
       " 'col_ptr.npy',\n",
       " 'row_ptr.npy']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the same thing for the infer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make input directory \n",
    "input_dir_infer = notebook_workdir / \"celltype-bench-dataset-infer\"\n",
    "input_dir_infer.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set paths for data and results \n",
    "data_dir_infer = notebook_workdir / \"celltype-bench-dataset-infer-data\"\n",
    "result_path_infer = notebook_workdir / \"results_infer.pt\"\n",
    "\n",
    "# Shuffle all indices with random seed \n",
    "with random_seed(32):\n",
    "    indices = list(range(len(inferData)))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "micro_batch_size:int = 32\n",
    "num_steps:int = 256\n",
    "selection = sorted(indices[:micro_batch_size*num_steps])\n",
    "\n",
    "# Write the infer data to the input directory \n",
    "h5ad_outfile_infer = input_dir_infer / \"hs-celltype-bench.h5ad\"\n",
    "inferData.write_h5ad(h5ad_outfile_infer)\n",
    "\n",
    "# Run the conversion to scdl\n",
    "!convert_h5ad_to_scdl --data-path {input_dir_infer} --save-path {data_dir_infer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the output files were written "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['version.json',\n",
       " 'features',\n",
       " 'data.npy',\n",
       " 'metadata.json',\n",
       " 'col_ptr.npy',\n",
       " 'row_ptr.npy']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir_infer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell Type Classificaton with Geneformer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now in an optimized format to be ingested by Geneformer and we can run inference. In this lab we will be using [Geneformer through BioNeMo Frameworks](https://docs.nvidia.com/bionemo-framework/2.3/models/geneformer/) to run model inference. \n",
    "\n",
    "BioNeMo is a software ecosystem produced by NVIDIA for the development and deployment of life sciences-oriented artificial intelligence models. BioNeMo provides a set of tools to help researchers build, train, and deploy AI models for various biological applications.\n",
    "\n",
    "- BioNeMo Framework: a free-to-use collection of programming tools and packages offering access to optimized, pre-trained biomolecular models and workflows. The framework enables building and customizing models, including training and fine-tuning. Capabilities span various workloads and therapeutic modalities, such as molecular generation, protein structure prediction, protein-ligand, and representation learning.\n",
    "\n",
    "[Geneformer](https://www.nature.com/articles/s41586-023-06139-9) is a foundational single-cell RNA (scRNA) language model using a BERT architecture trained on millions of single-cell RNA sequences. It captures gene co-expression patterns to learn cellular representations, enabling predictive tasks across biology and medicine. Geneformer is trained on a masked language model (MLM) objective, where expression rank-ordered \"gene tokens\" in single-cell RNA sequences are masked, replaced, or left unchanged, and the model learns to predict these masked genes based on context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the BioNeMo [helper script](https://docs.nvidia.com/bionemo-framework/latest/user-guide/getting-started/development/) to download the Geneformer 106M parameter model checkpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneformer_106m_out = !download_bionemo_data \"geneformer/106M_240530:2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result includes a list of outputs, the last one is the path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneformer_106m = geneformer_106m_out[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path_106m = notebook_workdir / \"results_106m.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some hyperparameters based on your system. Check the GPU resources available using `nvidia-smi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 1\n",
    "micro_batch_size:int = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo W 2025-10-23 13:36:12 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pyannote/core/notebook.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "      cm = get_cmap(\"Set1\")\n",
      "    \n",
      "Downloading data from 'nvidia/clara/singlecell-testdata:2.0' to file '/root/.cache/bionemo/d8e3ea569bc43768c24aa651aff77722df202078415528497c22394046b08cc3-singlecell-scdltestdata-20241203.tar.gz'.\n",
      "{\n",
      "    \"download_end\": \"2025-10-23 13:36:30\",\n",
      "    \"download_start\": \"2025-10-23 13:36:15\",\n",
      "    \"download_time\": \"14s\",\n",
      "    \"files_downloaded\": 1,\n",
      "    \"local_path\": \"/root/.cache/bionemo/tmpcz4s8vkz/singlecell-testdata_v2.0\",\n",
      "    \"size_downloaded\": \"224.17 MB\",\n",
      "    \"status\": \"COMPLETED\"\n",
      "}\n",
      "Untarring contents of '/root/.cache/bionemo/d8e3ea569bc43768c24aa651aff77722df202078415528497c22394046b08cc3-singlecell-scdltestdata-20241203.tar.gz' to '/root/.cache/bionemo/d8e3ea569bc43768c24aa651aff77722df202078415528497c22394046b08cc3-singlecell-scdltestdata-20241203.tar.gz.untar'\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] Downloading resource: https://huggingface.co/ctheodoris/Geneformer/resolve/main/geneformer/gene_dictionaries_30m/gene_name_id_dict_gc30M.pkl?download=true\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] Downloading resource: https://huggingface.co/ctheodoris/Geneformer/resolve/main/geneformer/gene_dictionaries_30m/gene_median_dictionary_gc30M.pkl?download=true\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] *************** Preprocessing Finished ************\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: True\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-10-23 13:36:36 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[WARNING  | /usr/local/lib/python3.12/dist-packages/bionemo/llm/model/config.py]: Loading /root/.cache/bionemo/7d67a526379eb8581f2aaaf03425ae9ec81a38570b24ddc8b22818e5d26ea772-geneformer_106M_240530_nemo2.tar.gz.untar\n",
      "[NeMo I 2025-10-23 13:36:37 nemo_logging:393] Padded vocab_size: 25472, original vocab_size: 25429, dummy tokens: 43.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo W 2025-10-23 13:36:37 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-10-23 13:36:37 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 106808960\n"
     ]
    }
   ],
   "source": [
    "!infer_geneformer \\\n",
    "    --data-dir {data_dir_ref} \\\n",
    "    --checkpoint-path {geneformer_106m} \\\n",
    "    --results-path {result_path_ref} \\\n",
    "    --micro-batch-size {micro_batch_size} \\\n",
    "    --seq-len 2048 \\\n",
    "    --num-dataset-workers 10 \\\n",
    "    --num-gpus {num_gpus} \\\n",
    "    --include-input-ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference on ref data took around 17 minutes on 1 A100 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the output files containing the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predictions__rank_0.pt']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(result_path_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo W 2025-10-23 13:54:38 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pyannote/core/notebook.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "      cm = get_cmap(\"Set1\")\n",
      "    \n",
      "[NeMo W 2025-10-23 13:54:43 nemo_logging:405] Tokenizer vocab file: /root/.cache/bionemo/d8e3ea569bc43768c24aa651aff77722df202078415528497c22394046b08cc3-singlecell-scdltestdata-20241203.tar.gz.untar/cellxgene_2023-12-15_small_processed_scdl/train/geneformer.vocab already exists. Overwriting...\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] Resource already exists, skipping download: https://huggingface.co/ctheodoris/Geneformer/resolve/main/geneformer/gene_dictionaries_30m/gene_name_id_dict_gc30M.pkl?download=true\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] Resource already exists, skipping download: https://huggingface.co/ctheodoris/Geneformer/resolve/main/geneformer/gene_dictionaries_30m/gene_median_dictionary_gc30M.pkl?download=true\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] *************** Preprocessing Finished ************\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: True\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-10-23 13:54:43 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[WARNING  | /usr/local/lib/python3.12/dist-packages/bionemo/llm/model/config.py]: Loading /root/.cache/bionemo/7d67a526379eb8581f2aaaf03425ae9ec81a38570b24ddc8b22818e5d26ea772-geneformer_106M_240530_nemo2.tar.gz.untar\n",
      "[NeMo I 2025-10-23 13:54:44 nemo_logging:393] Padded vocab_size: 25472, original vocab_size: 25429, dummy tokens: 43.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo W 2025-10-23 13:54:44 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-10-23 13:54:44 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 106808960\n"
     ]
    }
   ],
   "source": [
    "!infer_geneformer \\\n",
    "    --data-dir {data_dir_infer} \\\n",
    "    --checkpoint-path {geneformer_106m} \\\n",
    "    --results-path {result_path_infer} \\\n",
    "    --micro-batch-size {micro_batch_size} \\\n",
    "    --seq-len 2048 \\\n",
    "    --num-dataset-workers 10 \\\n",
    "    --num-gpus {num_gpus} \\\n",
    "    --include-input-ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference on infer data took around 4 minutes on 1 A100 GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the output files containing the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predictions__rank_0.pt']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(result_path_infer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we want to add these classifications to our main AnnData object as an `obsm`. Below is a helper script for that operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_results_to_adata(adata, result_path, num_gpus, batchsize):\n",
    "    data_sets = []\n",
    "    for i in range(num_gpus):\n",
    "        inter_emb = torch.load(result_path / f\"predictions__rank_{i}.pt\", weights_only=False)['embeddings'].float().cpu().numpy()\n",
    "        data_sets.append(inter_emb)\n",
    "    global_batch_size = batchsize*num_gpus\n",
    "    out = np.zeros((adata.shape[0],data_sets[0].shape[1]),dtype=np.float32)\n",
    "    for i in range(num_gpus):\n",
    "        emd = data_sets[i]\n",
    "        n_batches = (emd.shape[0]+batchsize-1)//batchsize\n",
    "        for j in range(n_batches):\n",
    "            start = j*batchsize\n",
    "            stop = min((j+1)*batchsize, emd.shape[0])\n",
    "            start_global = i*batchsize +j*global_batch_size\n",
    "            stop_global = start_global +stop-start\n",
    "            out[start_global:stop_global] = emd[start:stop]\n",
    "    adata.obsm[\"X_geneformer\"] = out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the ref data predictions to the anndata object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_results_to_adata(refData, result_path_ref, num_gpus, micro_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the `obsm` attribute now has a `X_geneformer` array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AxisArrays with keys: X_geneformer"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refData.obsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the same, we can see that for each cell, there is an embedding vector of length 768 that represents the cell type prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172170, 768)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refData.obsm[\"X_geneformer\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for `inferData`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40443, 768)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_results_to_adata(inferData, result_path_infer, num_gpus, micro_batch_size)\n",
    "inferData.obsm\n",
    "inferData.obsm[\"X_geneformer\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Label Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the geneformer embeddings, we can train the Random Forest Classifier for the Label Transfer task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training and test dataset for label transfer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(refData.obsm[\"X_geneformer\"], refData.obs[\"cell_type\"].cat.codes.to_numpy(), random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model, we will create a [RandomForestClassifier](https://docs.rapids.ai/api/cuml/stable/api/#cuml.ensemble.RandomForestClassifier) using cuML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.ensemble import RandomForestClassifier as cuRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cuRF(random_state=0, n_streams=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_RF = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on the held out test labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# memory management issue (close other notebooks?) \n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the training accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cupy import asnumpy\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9047928815370676"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(asnumpy(y_test), asnumpy(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Label Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the label transfer model is trained, we can use it to run predictions on the test set to evaluate the inference performance of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(inferData.obsm[\"X_geneformer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy, precision, recall, and F1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8274608708552778"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(inferData.obs[\"cell_type\"].cat.codes.to_numpy(), asnumpy(test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8611697210617062"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(inferData.obs[\"cell_type\"].cat.codes.to_numpy(), asnumpy(test_predictions), average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7866206676881882"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(inferData.obs[\"cell_type\"].cat.codes.to_numpy(), asnumpy(test_predictions), average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8122860954672174"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(inferData.obs[\"cell_type\"].cat.codes.to_numpy(), asnumpy(test_predictions), average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook successfully demonstrates a stateâ€‘ofâ€‘theâ€‘art workflow where singleâ€‘cell gene expression data are converted into informative embeddings using a foundation model -- Geneformer, unifying single-cell datasets by transferring labels across technologies (e.g., different sequencing assays). \n",
    "\n",
    "This integrated approach enables scalable, cross-dataset analysis for large-scale biological discovery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now **shut down the kernel** so this notebook stops using memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Executing the provided code cell will shut down the kernel and activate a popup indicating that the kernel has restarted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
